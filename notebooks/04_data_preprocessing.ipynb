{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0f28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8ba1b",
   "metadata": {},
   "source": [
    "Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6b345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_station(station_dict):\n",
    "    nwm_df = station_dict['nwm']\n",
    "    usgs_df = station_dict['usgs']\n",
    "\n",
    "    # Bring DateTime back as a column if it's the index\n",
    "    if usgs_df.index.name == 'DateTime':\n",
    "        usgs_df = usgs_df.reset_index()\n",
    "\n",
    "    # Handle datetime conversion and strip timezone\n",
    "    usgs_df['DateTime'] = pd.to_datetime(usgs_df['DateTime']).dt.round('h')\n",
    "    usgs_df['DateTime'] = usgs_df['DateTime'].dt.tz_localize(None)\n",
    "\n",
    "    nwm_df['model_output_valid_time'] = pd.to_datetime(nwm_df['model_output_valid_time'])\n",
    "    nwm_df['model_output_valid_time'] = nwm_df['model_output_valid_time'].dt.tz_localize(None)\n",
    "\n",
    "    # Find the streamflow column in NWM data\n",
    "    flow_col = next((col for col in nwm_df.columns if 'streamflow' in col.lower()), None)\n",
    "    if flow_col is None:\n",
    "        raise KeyError(\"Could not find a streamflow column in NWM data\")\n",
    "\n",
    "    # Merge on timestamp\n",
    "    merged = pd.merge(\n",
    "        nwm_df,\n",
    "        usgs_df,\n",
    "        how='inner',\n",
    "        left_on='model_output_valid_time',\n",
    "        right_on='DateTime'\n",
    "    )\n",
    "\n",
    "    merged = merged[[\n",
    "        'model_initialization_time',\n",
    "        'model_output_valid_time',\n",
    "        flow_col,\n",
    "        'USGSFlowValue'\n",
    "    ]]\n",
    "\n",
    "    merged = merged.rename(columns={\n",
    "        flow_col: 'NWM_streamflow',\n",
    "        'USGSFlowValue': 'USGS_streamflow'\n",
    "    })\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e77429",
   "metadata": {},
   "source": [
    "Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7291b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = Path(\"../data/processed/station_data.pkl\")\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    station_data = pickle.load(f)\n",
    "\n",
    "assert 'station1' in station_data and 'station2' in station_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af4512",
   "metadata": {},
   "source": [
    "Preprocess Both Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0647694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station1_df = preprocess_station(station_data['station1'])\n",
    "station2_df = preprocess_station(station_data['station2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e933032",
   "metadata": {},
   "source": [
    "Add lead_time, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4d7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [station1_df, station2_df]:\n",
    "    df['model_initialization_time'] = pd.to_datetime(df['model_initialization_time'])\n",
    "    df['lead_time'] = (df['model_output_valid_time'] - df['model_initialization_time']).dt.total_seconds() / 3600\n",
    "    df['year'] = df['model_output_valid_time'].dt.year\n",
    "    df['month'] = df['model_output_valid_time'].dt.month\n",
    "    df['day'] = df['model_output_valid_time'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae5139",
   "metadata": {},
   "source": [
    "Save Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2bcdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved station1_processed.parquet and station2_processed.parquet\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "station1_df.to_parquet(output_dir / \"station1_processed.parquet\", index=False)\n",
    "station2_df.to_parquet(output_dir / \"station2_processed.parquet\", index=False)\n",
    "\n",
    "print(\"Saved station1_processed.parquet and station2_processed.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
