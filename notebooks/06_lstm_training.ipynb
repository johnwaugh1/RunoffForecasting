{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers, callbacks, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306be6b",
   "metadata": {},
   "source": [
    "Set random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7958f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83933e0e",
   "metadata": {},
   "source": [
    "Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8fddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "station1_scaled = pd.read_parquet('../data/processed/station1_final_processed.parquet')\n",
    "station2_scaled = pd.read_parquet('../data/processed/station2_final_processed.parquet')\n",
    "\n",
    "station1_original = pd.read_csv('../data/processed/station1_processed.csv')\n",
    "station2_original = pd.read_csv('../data/processed/station2_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1fd2a",
   "metadata": {},
   "source": [
    "Convert datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c686bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [station1_original, station2_original]:\n",
    "    df['model_output_valid_time'] = pd.to_datetime(df['model_output_valid_time'])\n",
    "    df['model_initialization_time'] = pd.to_datetime(df['model_initialization_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024f0b8",
   "metadata": {},
   "source": [
    "Merge scaled and original data to recover model_initialization_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97942cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time_mapping_station1 = station1_original.set_index('model_output_valid_time')['model_initialization_time'].to_dict()\n",
    "init_time_mapping_station2 = station2_original.set_index('model_output_valid_time')['model_initialization_time'].to_dict()\n",
    "\n",
    "station1_scaled['model_initialization_time'] = station1_scaled['model_output_valid_time'].map(init_time_mapping_station1)\n",
    "station2_scaled['model_initialization_time'] = station2_scaled['model_output_valid_time'].map(init_time_mapping_station2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d15e0",
   "metadata": {},
   "source": [
    "Calculate lead_time (in hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be40385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station1_scaled['lead_time'] = (station1_scaled['model_output_valid_time'] - station1_scaled['model_initialization_time']).dt.total_seconds() / 3600\n",
    "station2_scaled['lead_time'] = (station2_scaled['model_output_valid_time'] - station2_scaled['model_initialization_time']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8608b8",
   "metadata": {},
   "source": [
    "Add residual column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b72b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "station1_scaled['residual'] = (station1_scaled['USGS_streamflow'] - station1_scaled['NWM_streamflow'])\n",
    "station2_scaled['residual'] = (station2_scaled['USGS_streamflow'] - station2_scaled['NWM_streamflow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6589e7",
   "metadata": {},
   "source": [
    "Combine station1 and station2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cd3f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([station1_scaled, station2_scaled], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7bf10",
   "metadata": {},
   "source": [
    "Split into train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797237b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = combined.sort_values('model_output_valid_time')\n",
    "\n",
    "train_frac = 0.7\n",
    "val_frac = 0.15\n",
    "test_frac = 0.15\n",
    "\n",
    "n = len(full_data)\n",
    "train_end = int(n * train_frac)\n",
    "val_end = int(n * (train_frac + val_frac))\n",
    "\n",
    "train_data = full_data.iloc[:train_end]\n",
    "val_data = full_data.iloc[train_end:val_end]\n",
    "test_data = full_data.iloc[val_end:]\n",
    "\n",
    "X_train = train_data[feature_cols].values\n",
    "y_train = train_data[target_col].values\n",
    "\n",
    "X_val = val_data[feature_cols].values\n",
    "y_val = val_data[target_col].values\n",
    "\n",
    "X_test = test_data[feature_cols].values\n",
    "y_test = test_data[target_col].values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
