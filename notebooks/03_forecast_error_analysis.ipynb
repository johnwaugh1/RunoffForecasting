{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5cb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec5224",
   "metadata": {},
   "source": [
    "Add src directory to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99eef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from data_utils import align_forecast_observation, calculate_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a90e29",
   "metadata": {},
   "source": [
    "Load saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04e83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/processed/station_data.pkl', 'rb') as f:\n",
    "    station_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478b33a",
   "metadata": {},
   "source": [
    "Align forecasts with observations and analyze errors for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c786d529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Forecast error analysis for station1\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m    nwm_data[\u001b[33m'\u001b[39m\u001b[33mmodel_initialization_time\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(nwm_data[\u001b[33m'\u001b[39m\u001b[33mmodel_initialization_time\u001b[39m\u001b[33m'\u001b[39m]).dt.tz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Align NWM forecasts with USGS observations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m    aligned_data = \u001b[43malign_forecast_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnwm_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musgs_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m    \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAligned data points: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(aligned_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m    \u001b[38;5;66;03m# Save aligned data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnm\\Downloads\\RunoffForcasting_AIProject\\RunoffForecasting\\src\\data_utils.py:115\u001b[39m, in \u001b[36malign_forecast_observation\u001b[39m\u001b[34m(nwm_df, usgs_df)\u001b[39m\n\u001b[32m    112\u001b[39m forecast_value = row[\u001b[33m'\u001b[39m\u001b[33mstreamflow_value\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Find the closest observation time (within 30 minutes)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m time_diff = \u001b[43m(\u001b[49m\u001b[43musgs_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtotal_seconds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m time_diff = np.abs(time_diff)\n\u001b[32m    117\u001b[39m closest_idx = time_diff.argmin()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\extension.py:95\u001b[39m, in \u001b[36m_inherit_from_data.<locals>.method\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minplace\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot use inplace with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m result = \u001b[43mattr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m._data)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\timedeltas.py:786\u001b[39m, in \u001b[36mTimedeltaArray.total_seconds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    733\u001b[39m \u001b[33;03mReturn total duration of each element expressed in seconds.\u001b[39;00m\n\u001b[32m    734\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m \u001b[33;03mIndex([0.0, 86400.0, 172800.0, 259200.0, 345600.0], dtype='float64')\u001b[39;00m\n\u001b[32m    784\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m pps = periods_per_second(\u001b[38;5;28mself\u001b[39m._creso)\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_mask_results\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43masi8\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mpps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:850\u001b[39m, in \u001b[36mDatetimeLikeArrayMixin._maybe_mask_results\u001b[39m\u001b[34m(self, result, fill_value, convert)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[33;03m    return if I have any nans; enables various perf speedups\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    848\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m._isnan.any())\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_mask_results\u001b[39m(\n\u001b[32m    851\u001b[39m     \u001b[38;5;28mself\u001b[39m, result: np.ndarray, fill_value=iNaT, convert=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    852\u001b[39m ) -> np.ndarray:\n\u001b[32m    853\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m    855\u001b[39m \u001b[33;03m    ----------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    867\u001b[39m \u001b[33;03m    This is an internal routine.\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hasna:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for station_name, data in station_data.items():\n",
    "    usgs_data = data['usgs']\n",
    "    nwm_data = data['nwm']\n",
    "    \n",
    "    print(f\"\\n\\n{'='*50}\")\n",
    "    print(f\"Forecast error analysis for {station_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "        \n",
    "    usgs_data.index = pd.to_datetime(usgs_data.index).tz_localize(None)\n",
    "    nwm_data['model_output_valid_time'] = pd.to_datetime(nwm_data['model_output_valid_time']).dt.tz_localize(None)\n",
    "    nwm_data['model_initialization_time'] = pd.to_datetime(nwm_data['model_initialization_time']).dt.tz_localize(None)\n",
    "    \n",
    " # Align NWM forecasts with USGS observations\n",
    "    aligned_data = align_forecast_observation(nwm_data, usgs_data)\n",
    "    \n",
    "    print(f\"Aligned data points: {len(aligned_data)}\")\n",
    "    \n",
    "    # Save aligned data\n",
    "    aligned_data.to_csv(f\"../data/processed/{station_name}_aligned_data.csv\", index=False)\n",
    "    \n",
    "    # Calculate error statistics by lead time\n",
    "    lead_times = sorted(aligned_data['lead_time'].unique())\n",
    "    \n",
    "    error_stats = []\n",
    "    metrics_by_lead = []\n",
    "    \n",
    "    for lead in lead_times:\n",
    "        lead_data = aligned_data[aligned_data['lead_time'] == lead]\n",
    "        \n",
    "        # Basic error statistics\n",
    "        stats = {\n",
    "            'lead_time': lead,\n",
    "            'count': len(lead_data),\n",
    "            'mean_error': lead_data['error'].mean(),\n",
    "            'std_error': lead_data['error'].std(),\n",
    "            'min_error': lead_data['error'].min(),\n",
    "            'max_error': lead_data['error'].max(),\n",
    "            'mean_abs_error': np.abs(lead_data['error']).mean()\n",
    "        }\n",
    "        error_stats.append(stats)\n",
    "        \n",
    "        # Calculate hydrologic metrics\n",
    "        metrics = calculate_metrics(lead_data['observed_value'], lead_data['forecast_value'])\n",
    "        metrics['lead_time'] = lead\n",
    "        metrics_by_lead.append(metrics)\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    error_stats_df = pd.DataFrame(error_stats)\n",
    "    metrics_df = pd.DataFrame(metrics_by_lead)\n",
    "    \n",
    "    # Save statistics\n",
    "    error_stats_df.to_csv(f\"../data/processed/{station_name}_error_stats.csv\", index=False)\n",
    "    metrics_df.to_csv(f\"../data/processed/{station_name}_metrics.csv\", index=False)\n",
    "    \n",
    "    # Create visualizations\n",
    "    \n",
    "    # Box plot of errors by lead time\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.boxplot(x='lead_time', y='error', data=aligned_data)\n",
    "    plt.title(f'{station_name} - NWM Forecast Error Distribution by Lead Time')\n",
    "    plt.xlabel('Lead Time (hours)')\n",
    "    plt.ylabel('Forecast Error (observed - forecasted, m³/s)')\n",
    "    plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../data/figures/{station_name}_error_by_leadtime.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot of error metrics by lead time\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(metrics_df['lead_time'], metrics_df['CC'], 'o-')\n",
    "    plt.title(f'{station_name} - Correlation Coefficient by Lead Time')\n",
    "    plt.xlabel('Lead Time (hours)')\n",
    "    plt.ylabel('CC')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(metrics_df['lead_time'], metrics_df['RMSE'], 'o-')\n",
    "    plt.title(f'{station_name} - RMSE by Lead Time')\n",
    "    plt.xlabel('Lead Time (hours)')\n",
    "    plt.ylabel('RMSE (m³/s)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(metrics_df['lead_time'], metrics_df['PBIAS'], 'o-')\n",
    "    plt.title(f'{station_name} - Percent Bias by Lead Time')\n",
    "    plt.xlabel('Lead Time (hours)')\n",
    "    plt.ylabel('PBIAS (%)')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(metrics_df['lead_time'], metrics_df['NSE'], 'o-')\n",
    "    plt.title(f'{station_name} - Nash-Sutcliffe Efficiency by Lead Time')\n",
    "    plt.xlabel('Lead Time (hours)')\n",
    "    plt.ylabel('NSE')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../data/figures/{station_name}_metrics_by_leadtime.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plot of observed vs forecasted for specific lead time\n",
    "    for lead in [1, 6, 12, 18]:\n",
    "        if lead not in lead_times:\n",
    "            continue\n",
    "            \n",
    "        lead_data = aligned_data[aligned_data['lead_time'] == lead]\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(lead_data['observed_value'], lead_data['forecast_value'], alpha=0.5)\n",
    "    \n",
    "        max_val = max(lead_data['observed_value'].max(), lead_data['forecast_value'].max())\n",
    "        min_val = min(lead_data['observed_value'].min(), lead_data['forecast_value'].min())\n",
    "        plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "        \n",
    "        plt.title(f'{station_name} - Observed vs Forecasted Flow (Lead Time = {lead} hours)')\n",
    "        plt.xlabel('Observed Flow (m³/s)')\n",
    "        plt.ylabel('Forecasted Flow (m³/s)')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../data/figures/{station_name}_obs_vs_forecast_lead{lead}.png\")\n",
    "        plt.show()   \n",
    "        \n",
    "    # Time series plot of observed and forecasted for specific initialization time\n",
    "    sample_init = np.random.choice(aligned_data['initialization_time'].unique())\n",
    "    sample_data = aligned_data[aligned_data['initialization_time'] == sample_init]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(sample_data['valid_time'], sample_data['observed_value'], 'o-', label='Observed')\n",
    "    plt.plot(sample_data['valid_time'], sample_data['forecast_value'], 's-', label='Forecasted')\n",
    "    plt.title(f'{station_name} - Observed vs Forecasted Flow\\nInitialization: {sample_init}')\n",
    "    plt.xlabel('Valid Time')\n",
    "    plt.ylabel('Flow (m³/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../data/figures/{station_name}_time_series_comparison.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Seasonality in errors\n",
    "    aligned_data['month'] = aligned_data['valid_time'].dt.month\n",
    "    \n",
    "    monthly_errors = aligned_data.groupby(['month', 'lead_time'])['error'].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for lead in [1, 6, 12, 18]:\n",
    "        if lead not in lead_times:\n",
    "            continue\n",
    "            \n",
    "        lead_monthly = monthly_errors[monthly_errors['lead_time'] == lead]\n",
    "        if not lead_monthly.empty:\n",
    "            plt.plot(lead_monthly['month'], lead_monthly['error'], 'o-', label=f'Lead {lead}h')\n",
    "    \n",
    "    plt.title(f'{station_name} - Monthly Mean Forecast Error by Lead Time')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Mean Error (m³/s)')\n",
    "    plt.xticks(range(1, 13))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../data/figures/{station_name}_monthly_errors.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Analysis complete for {station_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
